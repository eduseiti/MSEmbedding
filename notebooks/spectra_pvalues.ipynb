{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "import sys\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Pvalues calculations for PXD000561, REMOVING the experiment files without identifications\n",
    "#\n",
    "\n",
    "PVALUES_MIXEDSPECTRACRUX_FULL_01=\"/media/eduseiti/data_storage_1TB/unicamp/PXD000561/mixedSpectraCrux_experiments_removing_files_without_identifications_pvalues/300.dat_allSpectraPvalues.bin\"\n",
    "PVALUES_MIXEDSPECTRACRUX_FULL_02=\"/media/eduseiti/data_storage_1TB/unicamp/PXD000561/mixedSpectraCrux_experiments_removing_files_without_identifications_pvalues/474.dat_allSpectraPvalues.bin\"\n",
    "PVALUES_MIXEDSPECTRACRUX_FULL_03=\"/media/eduseiti/data_storage_1TB/unicamp/PXD000561/mixedSpectraCrux_experiments_removing_files_without_identifications_pvalues/560.dat_allSpectraPvalues.bin\"\n",
    "PVALUES_MIXEDSPECTRACRUX_FULL_04=\"/media/eduseiti/data_storage_1TB/unicamp/PXD000561/mixedSpectraCrux_experiments_removing_files_without_identifications_pvalues/632.dat_allSpectraPvalues.bin\"\n",
    "PVALUES_MIXEDSPECTRACRUX_FULL_05=\"/media/eduseiti/data_storage_1TB/unicamp/PXD000561/mixedSpectraCrux_experiments_removing_files_without_identifications_pvalues/715.dat_allSpectraPvalues.bin\"\n",
    "PVALUES_MIXEDSPECTRACRUX_FULL_06=\"/media/eduseiti/data_storage_1TB/unicamp/PXD000561/mixedSpectraCrux_experiments_removing_files_without_identifications_pvalues/818.dat_allSpectraPvalues.bin\"\n",
    "PVALUES_MIXEDSPECTRACRUX_FULL_07=\"/media/eduseiti/data_storage_1TB/unicamp/PXD000561/mixedSpectraCrux_experiments_removing_files_without_identifications_pvalues/1005.dat_allSpectraPvalues.bin\"\n",
    "\n",
    "#\n",
    "# Can use the same .tsv file, since the access is done through the .mgf filename.\n",
    "#\n",
    "\n",
    "COUNTS_MIXEDSPECTRACRUX_FULL=\"/media/eduseiti/bigdata01/unicamp/doutorado/clustering/linfeng/sample/pvalue/PXD000561_all_experiments_spectra_count.tsv\"\n",
    "LIST_OF_FILES_FOR_PVALUES=\"/media/eduseiti/data_storage_1TB/unicamp/PXD000561/PXD000561_all_experiments_removing_files_without_identifications.txt\"\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Initial pvalues calculations for PXD000561, WITHOUT removing the experiment files without identifications\n",
    "#\n",
    "\n",
    "# PVALUES_MIXEDSPECTRACRUX_FULL_01=\"/media/eduseiti/bigdata01/unicamp/doutorado/clustering/linfeng/sample/pvalue/PXD000561_all_experiments_pvalues/300.dat_allSpectraPvalues.bin\"\n",
    "# PVALUES_MIXEDSPECTRACRUX_FULL_02=\"/media/eduseiti/bigdata01/unicamp/doutorado/clustering/linfeng/sample/pvalue/PXD000561_all_experiments_pvalues/474.dat_allSpectraPvalues.bin\"\n",
    "# PVALUES_MIXEDSPECTRACRUX_FULL_03=\"/media/eduseiti/bigdata01/unicamp/doutorado/clustering/linfeng/sample/pvalue/PXD000561_all_experiments_pvalues/560.dat_allSpectraPvalues.bin\"\n",
    "# PVALUES_MIXEDSPECTRACRUX_FULL_04=\"/media/eduseiti/bigdata01/unicamp/doutorado/clustering/linfeng/sample/pvalue/PXD000561_all_experiments_pvalues/632.dat_allSpectraPvalues.bin\"\n",
    "# PVALUES_MIXEDSPECTRACRUX_FULL_05=\"/media/eduseiti/bigdata01/unicamp/doutorado/clustering/linfeng/sample/pvalue/PXD000561_all_experiments_pvalues/715.dat_allSpectraPvalues.bin\"\n",
    "# PVALUES_MIXEDSPECTRACRUX_FULL_06=\"/media/eduseiti/bigdata01/unicamp/doutorado/clustering/linfeng/sample/pvalue/PXD000561_all_experiments_pvalues/818.dat_allSpectraPvalues.bin\"\n",
    "# PVALUES_MIXEDSPECTRACRUX_FULL_07=\"/media/eduseiti/bigdata01/unicamp/doutorado/clustering/linfeng/sample/pvalue/PXD000561_all_experiments_pvalues/1005.dat_allSpectraPvalues.bin\"\n",
    "\n",
    "# COUNTS_MIXEDSPECTRACRUX_FULL=\"/media/eduseiti/bigdata01/unicamp/doutorado/clustering/linfeng/sample/pvalue/PXD000561_all_experiments_spectra_count.tsv\"\n",
    "\n",
    "\n",
    "#\n",
    "# Original experiments from PXD000561, selected for the first tests of \"mixedSpectraCrux\"\n",
    "#\n",
    "\n",
    "# PVALUES_MIXEDSPECTRACRUX=\"/mnt/f633ac7c-3153-4566-a009-229a0ae5f8a1/unicamp/doutorado/clustering/linfeng/sample/mixedSpectraCrux_experiments_pvalues/300.dat_allSpectraPvalues.bin\"\n",
    "# COUNTS_MIXEDSPECTRACRUX=\"/media/eduseiti/ebee9cb2-c63c-48bf-b862-004aba7612ee/unicamp/mixedSpectraCrux/mixedSpectraCrux_experiment_spectra_count.tsv\"\n",
    "\n",
    "\n",
    "#\n",
    "# Initial test data - Lifeng 10% sample\n",
    "#\n",
    "\n",
    "# PVALUES_FILE=\"/mnt/f633ac7c-3153-4566-a009-229a0ae5f8a1/unicamp/doutorado/clustering/linfeng/sample/test_pvalues_fix/400.dat_allSpectraPvalues.bin\"\n",
    "# IDS_FILE=\"/mnt/f633ac7c-3153-4566-a009-229a0ae5f8a1/unicamp/doutorado/clustering/linfeng/sample/identifications_sample_0.1_nterm/sample_experiment_identifications/percolator.target.psms.txt\"\n",
    "# COUNTS_FILE=\"/mnt/f633ac7c-3153-4566-a009-229a0ae5f8a1/unicamp/doutorado/spectra_count.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the identifications minimum score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENTS_MGF_DEFINITIONS_FOLDER=\"/media/eduseiti/data_storage_500MB/unicamp/PXD000561\"\n",
    "\n",
    "# sys.path.insert(1, EXPERIMENTS_MGF_DEFINITIONS_FOLDER)\n",
    "\n",
    "# import original_experiments_mgf_definitions\n",
    "import all_experiments_mgf_definitions as definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For q < 0.01\n",
    "\n",
    "# all_identifications_to_use = definitions.IDENTIFICATIONS\n",
    "\n",
    "# For q < 0.001\n",
    "\n",
    "all_identifications_to_use = definitions.IDENTIFICATIONS_Q_001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"all_experiments_mgf_definitions\" holds data structures used by the PXD000561.py code in the model to travel across the data structures of that work experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_identifications_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below is just a verification of the existing files; does not need to be executed\n",
    "\n",
    "This dataframe contains the spectra count for each .mgf file, in the same sequence as given to the maracluster to calculate the pvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countsdf = pd.read_csv(COUNTS_MIXEDSPECTRACRUX_FULL, sep=\"\\t\")\n",
    "\n",
    "print(countsdf)\n",
    "\n",
    "print(countsdf['spectra count'].sum())\n",
    "\n",
    "countsa = np.array(countsdf)\n",
    "\n",
    "print(countsa[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, verify if the number of files listed for each experiment matches the whole total for that experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "with open(\"/media/eduseiti/data_storage_500MB/unicamp/PXD000561/PXD000561_all_experiments.txt\", \"r\") as inputFile:\n",
    "    \n",
    "    structure_name = \"\"\n",
    "    last_index = 0\n",
    "    how_many = 0\n",
    "    \n",
    "    while True:\n",
    "        line = inputFile.readline()\n",
    "\n",
    "        if not line:\n",
    "            break\n",
    "            \n",
    "        hasFile = re.match(\".+\\/(.+)\\_[0-9]{1,2}\\_f([0-9]{2})\\.mgf$\", line)\n",
    "        \n",
    "        if not hasFile:\n",
    "            print(\"Could not match: peaks file={}, mgf file={}\".format(countsa[i][0], line))\n",
    "        else:\n",
    "            if hasFile.group(1) != structure_name:\n",
    "                if len(structure_name) > 0:\n",
    "                    if how_many < last_index:\n",
    "                        print(\"This one is missing: {}, counted={} files, last index={}\".format(structure_name, how_many, last_index))\n",
    "                    else:\n",
    "                        print(\"Correct: {}, counted={} files, last index={}\".format(structure_name, how_many, last_index))\n",
    "                    \n",
    "                    how_many = 0\n",
    "                    \n",
    "                structure_name = hasFile.group(1)\n",
    "                how_many += 1\n",
    "            else:\n",
    "                how_many += 1\n",
    "                last_index = int(hasFile.group(2))\n",
    "            \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del sys.modules['all_experiments_mgf_definitions']\n",
    "# del definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting here is the code to merge the maracluster pvalues with the dataset identification files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER=\"/media/eduseiti/data_storage_1TB/unicamp/PXD000561/all_experiments_q0001_filtered_identifications_original_with_pvalues\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRUCT_FIELDS = \"IId\"\n",
    "NO_PVALUE = sys.maxsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function will decode the binary file created by maracluster with each spectra pvalue\n",
    "\n",
    "The structure will contain the pvalues calculated for each spectra inside the .mgf file passed as parameter, in the order given by the files list given to maracluster as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_pvalues_file(pvalues_filename):\n",
    "    \n",
    "    pvalues = []\n",
    "\n",
    "    with open(pvalues_filename, \"rb\") as inputFile:\n",
    "        while True:\n",
    "            record = inputFile.read(struct.calcsize(STRUCT_FIELDS))\n",
    "\n",
    "            if not record:\n",
    "                break\n",
    "            else:\n",
    "                unpacked = struct.unpack_from(STRUCT_FIELDS, record)\n",
    "                \n",
    "                pvalues.append(unpacked)\n",
    "                \n",
    "                if math.isnan(unpacked[2]):\n",
    "                    print(\"nan: {}\".format(record))\n",
    "\n",
    "    print(\"Decoded {} pvalues from {}\".format(len(pvalues), pvalues_filename))\n",
    "    \n",
    "    return np.array(pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pvalues_histogram(pvalues):\n",
    "    \n",
    "    pvalues_df = pd.DataFrame(pvalues, columns = [\"file\", \"scannr\", \"pvalue\"])\n",
    "    \n",
    "    print(pvalues_df['pvalue'].describe(percentiles=list(np.round(np.arange(0.0, 1.0, 0.05), 2))))\n",
    "    \n",
    "    pvalues_histogram, pvalues_bin_edges = np.histogram(pvalues_df['pvalue'], 1000)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(go.Bar(y=pvalues_histogram,\n",
    "                         x=pvalues_bin_edges[1:],\n",
    "                         marker_color='red'))\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    return pvalues_df, pvalues_histogram, pvalues_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues_01 = decode_pvalues_file(PVALUES_MIXEDSPECTRACRUX_FULL_01)\n",
    "pvalues_02 = decode_pvalues_file(PVALUES_MIXEDSPECTRACRUX_FULL_02)\n",
    "pvalues_03 = decode_pvalues_file(PVALUES_MIXEDSPECTRACRUX_FULL_03)\n",
    "pvalues_04 = decode_pvalues_file(PVALUES_MIXEDSPECTRACRUX_FULL_04)\n",
    "pvalues_05 = decode_pvalues_file(PVALUES_MIXEDSPECTRACRUX_FULL_05)\n",
    "pvalues_06 = decode_pvalues_file(PVALUES_MIXEDSPECTRACRUX_FULL_06)\n",
    "pvalues_07 = decode_pvalues_file(PVALUES_MIXEDSPECTRACRUX_FULL_07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues = np.concatenate((pvalues_01, pvalues_02, pvalues_03, pvalues_04, pvalues_05, pvalues_06, pvalues_07))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pvalues_df, _, _ = plot_pvalues_histogram(pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues_df = pvalues_df.sort_values(['file', 'scannr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_identifications_to_use)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a validation of the pvalues dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues_array = pvalues_df.to_numpy()\n",
    "\n",
    "FILE_IDX = pvalues_df.columns.get_loc(\"file\")\n",
    "SCANNR_IDX = pvalues_df.columns.get_loc(\"scannr\")\n",
    "PVALUE_IDX = pvalues_df.columns.get_loc(\"pvalue\")\n",
    "\n",
    "current_file = -1\n",
    "first_scan = -1\n",
    "last_scan = -1\n",
    "num_of_pvalues = 0\n",
    "\n",
    "validation_result = []\n",
    "\n",
    "for i in range(len(pvalues_array)):\n",
    "    if pvalues_array[i][FILE_IDX] != current_file:\n",
    "        if current_file != -1:\n",
    "            new_result = {}\n",
    "            new_result['file idx'] = current_file\n",
    "            new_result['first scan'] = first_scan\n",
    "            new_result['last scan'] = last_scan\n",
    "            new_result['num of pvalues'] = num_of_pvalues\n",
    "            \n",
    "            validation_result.append(new_result)\n",
    "            \n",
    "        current_file = pvalues_array[i][FILE_IDX]\n",
    "        first_scan = pvalues_array[i][SCANNR_IDX]\n",
    "        num_of_pvalues = 1\n",
    "    else:\n",
    "        last_scan = pvalues_array[i][SCANNR_IDX]\n",
    "        num_of_pvalues += 1\n",
    "\n",
    "#\n",
    "# Append the last file result\n",
    "#\n",
    "\n",
    "new_result = {}\n",
    "new_result['file idx'] = current_file\n",
    "new_result['first scan'] = first_scan\n",
    "new_result['last scan'] = last_scan\n",
    "new_result['num of pvalues'] = num_of_pvalues\n",
    "\n",
    "validation_result.append(new_result)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result_df = pd.DataFrame(validation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pvalue_files_df = pd.read_csv(LIST_OF_FILES_FOR_PVALUES, names=[\"file\"], sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pvalue_files_df['file'] = list_of_pvalue_files_df['file'].str.split(\"/\").str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result_df['file'] = list_of_pvalue_files_df['file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_final_df = pd.merge(countsdf, validation_result_df, on='file', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_final_df.to_csv(os.path.join(OUTPUT_FOLDER, \"pvalues_validation.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the pvalues calculated in maracluster and set then in the corresponding experiment identification .tsv file\n",
    "\n",
    "This function will go through the list of experiments' identification files.\n",
    "\n",
    "For each file, it will go through the identifications and get the corresponding pvalue from the pvalues array created by maracluster, matching the FILE INDEX and the SCAN INDEX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pvalues_idx = 0\n",
    "\n",
    "total_ignored_pvalues_first = 0\n",
    "\n",
    "current_experiment_first_general_file_idx = 0\n",
    "current_experiment_total_files = 0\n",
    "\n",
    "pvalues_array = pvalues_df.to_numpy()\n",
    "\n",
    "FILE_IDX = pvalues_df.columns.get_loc(\"file\")\n",
    "SCANNR_IDX = pvalues_df.columns.get_loc(\"scannr\")\n",
    "PVALUE_IDX = pvalues_df.columns.get_loc(\"pvalue\")\n",
    "\n",
    "final_report = []\n",
    "\n",
    "pvalues_identifications = []\n",
    "\n",
    "#\n",
    "# Loop through the identifications .tsv files of each experiment\n",
    "#\n",
    "\n",
    "for file in all_identifications_to_use:\n",
    "        \n",
    "    # Advance in pvalues file until finishing the previous experiment file scans\n",
    "    \n",
    "    while pvalues_array[pvalues_idx][FILE_IDX] < current_experiment_first_general_file_idx + current_experiment_total_files:\n",
    "#         print(\"Advancing at the start. pvalues_array[pvalues_idx][FILE_IDX]={}, current_experiment_first_general_file_idx={}, current_experiment_total_files={}\".format(pvalues_array[pvalues_idx][FILE_IDX], \n",
    "#                                                                                                                                                                         current_experiment_first_general_file_idx, \n",
    "#                                                                                                                                                                         current_experiment_total_files))\n",
    "        pvalues_idx += 1\n",
    "        \n",
    "        total_ignored_pvalues_first += 1\n",
    "\n",
    "    if pvalues_array[pvalues_idx][FILE_IDX] > current_experiment_first_general_file_idx + current_experiment_total_files:\n",
    "        print(\"Missing pvalues for first experiment mgf file. pvalues_array[pvalues_idx][FILE_IDX]={}, current_experiment_first_general_file_idx={}, current_experiment_total_files={}\".format(pvalues_array[pvalues_idx][FILE_IDX], \n",
    "                                                                                                                                                                        current_experiment_first_general_file_idx, \n",
    "                                                                                                                                                                        current_experiment_total_files))\n",
    "        raise ValueError()\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Update the general file index to start the current experiment\n",
    "        \n",
    "    current_experiment_first_general_file_idx += current_experiment_total_files\n",
    "        \n",
    "        \n",
    "    # Read the current experiment data\n",
    "        \n",
    "    identifications_df = pd.read_csv(file, sep=\"\\t\")\n",
    "    \n",
    "    identifications_array = identifications_df.to_numpy()\n",
    "\n",
    "    ID_FILE_IDX = identifications_df.columns.get_loc(\"file_idx\")\n",
    "    ID_SCAN = identifications_df.columns.get_loc(\"scan\")\n",
    "    \n",
    "    \n",
    "    filename = file.split('/')[-1]\n",
    "        \n",
    "    current_experiment_total_files = len(definitions.MATCHES_TO_CRUX_FILES_LIST[filename])  \n",
    "    \n",
    "    identifications_pvalues = []\n",
    "    \n",
    "    experiment_identifications_without_pvalue = 0\n",
    "    processed_experiment_identifications = 0\n",
    "\n",
    "    print(\"\\n\\nHandling experiment={}, with {} files and a with total of {} identifications\".format(filename, \n",
    "                                                                                                  current_experiment_total_files, \n",
    "                                                                                                  identifications_df.shape[0]))\n",
    "       \n",
    "\n",
    "    last_processed_experiment_file = -1\n",
    "    how_many_identifications_without_pvalue = 0\n",
    "    \n",
    "    total_identifications_experiment_file = 0\n",
    "    identifications_without_pvalue_file = 0\n",
    "\n",
    "    new_results = {}\n",
    "        \n",
    "    #\n",
    "    # Go through all the identification scans for the given file\n",
    "    #\n",
    "        \n",
    "    for identification in identifications_array:\n",
    "        \n",
    "        experiment_general_file_idx = current_experiment_first_general_file_idx + identification[ID_FILE_IDX]\n",
    "\n",
    "        if last_processed_experiment_file != identification[ID_FILE_IDX]:\n",
    "            \n",
    "            if len(new_results) > 0:\n",
    "                new_results['total identifications'] = total_identifications_experiment_file\n",
    "                new_results['identifications with pvalue'] = total_identifications_experiment_file - identifications_without_pvalue_file\n",
    "                new_results['identifications without pvalue'] = identifications_without_pvalue_file\n",
    "                \n",
    "                final_report.append(new_results)\n",
    "                \n",
    "                total_identifications_experiment_file = 0\n",
    "                identifications_without_pvalue_file = 0                \n",
    "\n",
    "                \n",
    "            new_results = {}\n",
    "            \n",
    "            new_results['file'] = definitions.MATCHES_TO_CRUX_FILES_LIST[filename][identification[ID_FILE_IDX]]\n",
    "            \n",
    "            \n",
    "            print(\"\\n\\n---- Filling pvalues for experiment file index={}, general file index={}. Starting pvalue_idx={}\".format(identification[ID_FILE_IDX], \n",
    "                                                                                                                         experiment_general_file_idx, \n",
    "                                                                                                                         pvalues_idx))\n",
    "            last_processed_experiment_file = identification[ID_FILE_IDX]\n",
    "            \n",
    "            \n",
    "        processed_experiment_identifications += 1\n",
    "        total_identifications_experiment_file += 1\n",
    "        \n",
    "        # Advance pvalues file until reaching the experiment general file index\n",
    "        \n",
    "        while pvalues_array[pvalues_idx][FILE_IDX] < experiment_general_file_idx and pvalues_idx < len(pvalues_array) - 1:\n",
    "            pvalues_idx += 1\n",
    "        \n",
    "#         print(\"-- Handling experiment scan={}, pvalues index={}\".format(identification[ID_SCAN], pvalues_idx))\n",
    "\n",
    "        found_identification_scan = False\n",
    "\n",
    "        # Advance in pvalues file until reaching the identification scan\n",
    "\n",
    "        while (pvalues_array[pvalues_idx][SCANNR_IDX] < identification[ID_SCAN]) and \\\n",
    "              (pvalues_array[pvalues_idx][FILE_IDX] == experiment_general_file_idx) and pvalues_idx < len(pvalues_array) - 1:\n",
    "            pvalues_idx += 1\n",
    "\n",
    "        if pvalues_array[pvalues_idx][FILE_IDX] == experiment_general_file_idx:\n",
    "            if pvalues_array[pvalues_idx][SCANNR_IDX] == identification[ID_SCAN]:\n",
    "                identifications_pvalues.append(pvalues_array[pvalues_idx][PVALUE_IDX])\n",
    "\n",
    "#                 print(\"--- Found scan in pvalues index={}: {}\".format(pvalues_idx, pvalues_array[pvalues_idx]))\n",
    "\n",
    "\n",
    "                pvalues_identifications.append({\"file\": experiment_general_file_idx, \n",
    "                                                \"scan\": identification[ID_SCAN], \n",
    "                                                \"pvalue\": pvalues_array[pvalues_idx][PVALUE_IDX]})\n",
    "\n",
    "                pvalues_idx += 1\n",
    "\n",
    "                found_identification_scan = True\n",
    "\n",
    "\n",
    "        if not found_identification_scan:\n",
    "            identifications_pvalues.append(NO_PVALUE)\n",
    "\n",
    "#             print(\"------ Identification scan={} had no pvalue\".format(identification[ID_SCAN]))\n",
    "            how_many_identifications_without_pvalue += 1\n",
    "            identifications_without_pvalue_file += 1\n",
    "\n",
    "\n",
    "    # Save report information of the last experiment file\n",
    "    \n",
    "    if len(new_results) > 0:\n",
    "        new_results['total identifications'] = total_identifications_experiment_file\n",
    "        new_results['identifications with pvalue'] = total_identifications_experiment_file - identifications_without_pvalue_file\n",
    "        new_results['identifications without pvalue'] = identifications_without_pvalue_file\n",
    "\n",
    "        final_report.append(new_results)    \n",
    "    \n",
    "    identifications_df['pvalue'] = identifications_pvalues\n",
    "\n",
    "    identifications_df.to_csv(os.path.join(OUTPUT_FOLDER, file.split('/')[-1]), index=False, sep='\\t')\n",
    "\n",
    "    print(\"-- FINISHED after processing {}/{} identifications, with {} identifications scans without pvalues.\".format(processed_experiment_identifications, \n",
    "                                                                                                                      identifications_df.shape[0],\n",
    "                                                                                                                      how_many_identifications_without_pvalue))\n",
    "\n",
    "final_report_df = pd.DataFrame(final_report)\n",
    "\n",
    "datetime_execution = str(datetime.datetime.now())\n",
    "\n",
    "final_report_df.to_csv(os.path.join(OUTPUT_FOLDER, \"spectra_pvalues_report_\" + datetime_execution + \".tsv\"), index=False, sep='\\t')\n",
    "   \n",
    "pvalues_identifications_df = pd.DataFrame(pvalues_identifications)\n",
    "pvalues_identifications_df.to_csv(os.path.join(OUTPUT_FOLDER, \"pvalues_identifications\" + datetime_execution + \".tsv\"), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ignored_pvalues_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pvalues_identifications_df['pvalue'].describe(percentiles=list(np.round(np.arange(0.0, 1.0, 0.05), 2))))\n",
    "\n",
    "pvalues_identifications_histogram, pvalues_identifications_bin_edges = np.histogram(pvalues_identifications_df['pvalue'], 1000)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(y=pvalues_identifications_histogram,\n",
    "                     x=pvalues_identifications_bin_edges[1:],\n",
    "                     marker_color='red'))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues_df['pvalue'].describe(percentiles=list([0.1, 0.01, 0.001]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalues_identifications_df['pvalue'].describe(percentiles=list([0.1, 0.01, 0.001]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a report with the statistics for each individual file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.read_csv(COUNTS_MIXEDSPECTRACRUX_FULL, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report_totals_df = count_df.set_index('file').join(final_report_df.set_index('file'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report_totals_df.to_csv(os.path.join(OUTPUT_FOLDER, \"final_report_with_totals\" + datetime_execution + \".tsv\"), index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_report_totals_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
